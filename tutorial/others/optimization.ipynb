{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在机器学习和第一性原理计算的原子/离子relaxation中都涉及到了优化问题，对于机器学习，目标是寻找一组参数使得模型能够完成给定的目标，如给出原子坐标和元素种类后，能得到体系的能量和原子受力。对于原子/离子的relaxation问题，则是优化给定体系中原子/例子的坐标，使得每个原子/离子的受力最小（此时体系能量最低）。\n",
    "\n",
    "前面这两个例子中都用到了梯度下降法，这篇文章将围绕梯度下降法讲述一些基础概念，这些概念对于机器学习，原子/离子relaxation都有帮助。  \n",
    "\n",
    "首先看一个最简单的例子：二次函数优化，给定函数$y = x^2$，求函数最小值。这个例子比较简单，可以令函数的导数为0得到答案。但对于复杂的优化问题，我们没有函数的公式，无法求解析解，只能用数值计算求数值解，梯度下降法就是一种常用的数值求解方法。\n",
    "\n",
    "对于$y = x^2$，可以得到每一点的梯度（导数）公式为：$y = 2x$，然后随便猜一个初值，比如假设x=3这个点y值最小。然后计算得到x=3处的梯度grad = 2 \\* 3 = 6，接下来用下面的公式来更新x的位置：\n",
    "$$x_n = x_{n-1} - lr * grad$$\n",
    "`lr`可以对应机器学习中的学习率(learning rate),当`lr`设置得到并且n足够大时，我们就能找到$y = x^2$的最小值。下面我们来实现一下这个算法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f1f53a65be0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def func(x):\n",
    "    return x * x\n",
    "def grad(x):\n",
    "    return 2 * x\n",
    "\n",
    "x_guess = 3\n",
    "lr = 0.1\n",
    "threshold = 0.01\n",
    "\n",
    "def optimization(x_guess, lr, threshold):\n",
    "    x = x_guess\n",
    "    diff = 99999\n",
    "    y = func(x_guess)\n",
    "\n",
    "    xs = [x_guess]\n",
    "    ys = [y]\n",
    "    max_iter = 1000\n",
    "    while diff > threshold and max_iter > 0:\n",
    "        x = x - lr * grad(x)\n",
    "        xs.append(x)\n",
    "        max_iter -= 1\n",
    "        if len(xs) > 1:\n",
    "            # 当当前的x值与上一步x值的距离小于一定值时，认为已经找到了最小值\n",
    "            diff = abs(xs[-1] - xs[-2])\n",
    "\n",
    "        # 以下代码仅用于画图\n",
    "        ys.append(func(x))\n",
    "    return xs, ys\n",
    "    \n",
    "xs, ys = optimization(x_guess, lr, threshold)\n",
    "# 以下代码仅用于迭代过程可视化\n",
    "x_arr = np.linspace(-3, 3, 100)\n",
    "y_arr = [func(x) for x in x_arr]\n",
    "plt.scatter(x_arr, y_arr)\n",
    "plt.scatter(xs, ys, c='r',  marker='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number: 21\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.007130534626283792,\n",
       " 0.004563542160821628,\n",
       " 0.0029206669829258416,\n",
       " 0.0018692268690725384,\n",
       " 0.0011963051962064245]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"iteration number: {}\".format(len(xs)))\n",
    "ys[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的代码中使用了$\\left|x_n - x_{n-1}\\right| < threshold$来作为迭代终止的条件(max_iter=1000作为辅助判断条件，防止死循环)，可以看到一共迭代了21步，最后5步的值已经非常接近0了，几乎就是正确答案。神经网络训练中最常用的SGD算法，VASP中IBRION=3(steepest descent algorithm, POTIM可以认为是lr)算法归根结底都是上面的梯度下降法。\n",
    "\n",
    "在神经网络的训练中，当loss不再降低时，认为迭代次数已经足够，模型训练完成；在原子/离子relaxation问题中，当当前步和上一步中energy或者原子受力force差值的绝对值小于一定值时，认为迭代次数已经足够，结构优化完成。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化过程中的几个重要问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初猜值问题\n",
    "\n",
    "数值优化方法（梯度下降法是其中一种方法）都需要一个初始猜测值，并且计算的结果和迭代的次数都依赖初猜值。在$y = x^2$这个问题中，x_guess = 3需要迭代21次，而x_guess = 1只需要迭代16次，好的初始猜测值能明显加速模型收敛。\n",
    "\n",
    "在神经网络中，模型优化对于初始猜测值不算太敏感，一般使用随机初始化即可（框架可自动完成）。而第一性原理计算对初始猜测值就比较敏感了，细心的同学应该能发现，vasp做结构优化，第一个离子步中电子步的迭代一般都需要几十步，之后电子步迭代次数会明显降低。这就是因为第一个离子步中电子结构初始猜测比较差，需要较多步数才能收敛（注意：电子步的优化方法不是梯度下降，数值优化方法都存在初猜的问题），后面每一个离子步中的电子结构初猜，都使用前一个离子步中已经收敛的电子结构，因此只需少量迭代就能收敛。Guassian的一大优势就是电子初猜很不错，导致需要的迭代次数少于其它同类型软件。\n",
    "\n",
    "对于原子/离子relaxation同样存在这个问题，不借助工具随手画一个分子结构，将会需要很多离子步才能得到最终构型。但如果先用分子力学MM优化一下构型，作为一个好的初始猜测，再跑第一性原理构型优化，所需的离子步将会显著减少。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 局部最小值 vs 全局最小值\n",
    "数值优化方法（包括梯度下降法）一般只能找到局部最小值点，而很难或者几乎不可能找到全局最小值点，这导致不同的初猜值甚至可以得到完全不同的结果。\n",
    "考虑函数:\n",
    "$$y = x^4+x^3-7x^2-x+6$$\n",
    "其图像大致如下：\n",
    "\n",
    "![](figs/optimization-1.png)\n",
    "\n",
    "使用x_guess=-3.5和x_guess=0.5将会得到完全不同的结果，并且前者找到的是全局最小值，而后者只能找到局部最小值。\n",
    "\n",
    "对于神经网络来说，从实践来看，随机给一个初始猜测，最后训练的模型都差不多，没有显著区别。一种解释认为神经网络参数量太大（上亿参数），里面的极小值点效果都差不多，不一定非要找到全局最小值。\n",
    "\n",
    "对于第一性原理结构优化来说，不同的初始构型将会得到不同的结果。简单的问题如下图中的乙醇，O上的H原子可以旋转180°作为另一个初猜来做结构优化，最终可以得到两种不同构型的乙醇分子，并且两种结构的energy不一样。\n",
    "\n",
    "![](figs/optimization-2.png)\n",
    "\n",
    "复杂的问题例如表面催化反应，一般认为反应发生在缺陷处，计算时首先要构建不同的缺陷位点，然后找到表面能最低的那个构型再去计算化学反应。但缺陷位点构型不计其数，基本不可能找到最稳定的构型，只能靠人的经验判断，加上一些简化和假设来做计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lr值设置\n",
    "lr全称learning rate，是个经验性很强的参数。\n",
    "\n",
    "考虑函数$y = \\left|0.01*x\\right|$，它的导数$y^{\\prime} = 0.01$非常小，如果初猜x_guess=10，那需要迭代1000次才能找到正确结果，增大learning rate能加速收敛。\n",
    "\n",
    "当learning rate过大时，比如设置为0.9，此时跑$y = \\left|x\\right|$的例子，就会发现迭代进入死循环，数值求解的结果会在正确结果附近反复震荡，永不收敛。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    if x > 0: return x\n",
    "    else: return -x\n",
    "def grad(x):\n",
    "    if x > 0: return 1\n",
    "    else: return -1\n",
    "lr = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figs/optimization-3.png)\n",
    "\n",
    "在神经网络的训练中，对于lr设置有大量技巧，一般在训练开始时需要warm-up,即把learning rate从0缓慢增加到指定值，然后在训练过程中逐渐减小learning rate帮助模型收敛。把learning rate的值在整个训练过程中的变化画出来大概是这样子：  \n",
    "![](figs/optimization-4.png)  \n",
    "设lr=0.1,在训练开始的0-3000步，lr缓慢增长到0.1，然后采用指数(exp)或者sin下降法不断降低lr值，直到训练结束。Deepmd的模型训练就采用了exp下降法，不过没有实现warm-up步骤。  \n",
    "另外一种值得一提的lr调节方法是余弦退火法，在训练过程中不断增大lr又再次降低，在一定程度上可以帮助模型跳出局部最小值区域，找到更好的极小值点：  \n",
    "![](figs/optimization-5.png)\n",
    "\n",
    "总结一下，在神经网络模型训练初期，此时的初猜离真正的结果很远，需要较大的lr值来加速收敛（减小迭代次数），当模型接近真正的结果时，需要降低lr来减少震荡，帮助找到真正的结果。\n",
    "\n",
    "在VAPS的结构优化中，可以设置`IBRION=3`来启用梯度下降法，然后设置`POTIM`值来调节lr（在vasp中也称为步长），但`POTIM`是固定的，不能逐渐降低。官方文档推荐在构型比较糟糕的情况下，刚开始可以用梯度下降法快速迭代，之后需要换成`IBRION=1`准牛顿法（收敛速度最快）或者`IBRION=2`共轭梯度法（通用性最强）来找到精确解。  \n",
    "实际上，梯度下降法是一种收敛速度比较慢的算法，牛顿迭代法/准牛顿迭代法收敛速度远快于梯度下降法，但这两种方法代价很大，特别是牛顿迭代法需要求出体系的Hessian矩阵，对于结构优化只能退而求其次使用准牛顿法，而神经网络模型参数量经常几千万上亿，只能使用梯度下降法来优化。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "306f9674966356e6d2017fd9a046da687f90cc683eac906171c3efa96e5922a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
